{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code ([skip to narrative](#Outline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from bokeh.plotting import output_notebook, figure, ColumnDataSource, show\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.models import Arrow, NormalHead\n",
    "from bokeh.layouts import gridplot\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from util import read_word_list, read_word_groups\n",
    "from training import create_fasttext_model\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _new_section():\n",
    "    \n",
    "    state = {\n",
    "        'section': 1,\n",
    "    }\n",
    "    \n",
    "    def _display_new_section(title):\n",
    "        display(HTML(f'<h3>{state[\"section\"]}. {title}</h3>'))\n",
    "        state['section'] += 1\n",
    "        state['subsection'] = 1\n",
    "        \n",
    "    return _display_new_section\n",
    "\n",
    "new_section = _new_section()\n",
    "\n",
    "def pca_diagram():\n",
    "    import math\n",
    "    \n",
    "    pairs = [\n",
    "        [['she', .9], ['he', .65]],\n",
    "        [['woman', .95], ['man', .55]],\n",
    "    ]\n",
    "    \n",
    "    embedding_fig = figure(width=300, height=300, x_range=[-1.1, 1.1], y_range=[-1.1, 1.1])\n",
    "    embedding_fig.line(\n",
    "        x=[math.sin(i * 2 * math.pi / 200) for i in range(200)],\n",
    "        y=[math.cos(i * 2 * math.pi / 200) for i in range(200)],\n",
    "    )\n",
    "    for pair in pairs:\n",
    "        midpoint = [\n",
    "            sum(math.sin(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "            sum(math.cos(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "        ]\n",
    "        embedding_fig.x(x=midpoint[0], y=midpoint[1], line_width=3, size=10, color='#000000')\n",
    "        for word, fraction in pair:\n",
    "            x_pos = math.sin(fraction * 2 * math.pi)\n",
    "            y_pos = math.cos(fraction * 2 * math.pi)\n",
    "            embedding_fig.line(x=[midpoint[0], x_pos], y=[midpoint[1], y_pos], line_color='#000000')\n",
    "            embedding_fig.add_layout(Arrow(\n",
    "                x_start=midpoint[0], y_start=midpoint[1],\n",
    "                x_end=x_pos, y_end=y_pos,\n",
    "                end=NormalHead(size=10),\n",
    "            ))\n",
    "            embedding_fig.text(x=x_pos, y=y_pos, text=value(word))\n",
    "            \n",
    "    # FIXME\n",
    "    pca_vector = [[], []]\n",
    "    \n",
    "    pca_fig = figure(width=300, height=300, x_range=[-1.1, 1.1], y_range=[-1.1, 1.1])\n",
    "    pca_fig.x(x=0, y=0, line_width=3, size=10, color='#000000')\n",
    "    for pair in pairs:\n",
    "        midpoint = [\n",
    "            sum(math.sin(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "            sum(math.cos(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "        ]\n",
    "        for i, (word, fraction) in enumerate(pair):\n",
    "            x_pos = math.sin(fraction * 2 * math.pi) - midpoint[0]\n",
    "            y_pos = math.cos(fraction * 2 * math.pi) - midpoint[1]\n",
    "            pca_fig.line(x=[0, x_pos], y=[0, y_pos], line_color='#000000')\n",
    "            pca_fig.add_layout(Arrow(\n",
    "                x_start=0, y_start=0, x_end=x_pos, y_end=y_pos,\n",
    "                end=NormalHead(size=10),\n",
    "            ))\n",
    "            pca_fig.text(x=x_pos, y=y_pos, text=value(word))\n",
    "            if i == 0:\n",
    "                pca_vector[0].append(x_pos)\n",
    "                pca_vector[1].append(y_pos)\n",
    "    pca_vector = [\n",
    "        sum(pca_vector[0]) / len(pairs),\n",
    "        sum(pca_vector[1]) / len(pairs),\n",
    "    ]\n",
    "    pca_fig.line(\n",
    "        x=[i * pca_vector[0] for i in range(-200, 200)],\n",
    "        y=[i * pca_vector[1] for i in range(-200, 200)],\n",
    "        line_color='#C40000',\n",
    "    )\n",
    "    \n",
    "            \n",
    "    gender_fig = figure(width=300, height=300, x_range=[-1.1, 1.1], y_range=[-1.1, 1.1])\n",
    "    gender_fig.line(\n",
    "        x=[math.sin(i * 2 * math.pi / 200) for i in range(200)],\n",
    "        y=[math.cos(i * 2 * math.pi / 200) for i in range(200)],\n",
    "    )\n",
    "    for pair in pairs:\n",
    "        midpoint = [\n",
    "            sum(math.sin(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "            sum(math.cos(fraction * 2 * math.pi) for _, fraction in pair) / 2,\n",
    "        ]\n",
    "        gender_fig.x(\n",
    "            x=midpoint[0],\n",
    "            y=midpoint[1],\n",
    "            line_width=3,\n",
    "            size=10,\n",
    "            color='#000000',\n",
    "        )\n",
    "        for word, fraction in pair:\n",
    "            x_pos = math.sin(fraction * 2 * math.pi)\n",
    "            y_pos = math.cos(fraction * 2 * math.pi)\n",
    "            gender_fig.line(x=[midpoint[0], x_pos], y=[midpoint[1], y_pos], line_color='#000000')\n",
    "            gender_fig.add_layout(Arrow(\n",
    "                x_start=midpoint[0], y_start=midpoint[1],\n",
    "                x_end=x_pos, y_end=y_pos,\n",
    "                end=NormalHead(size=10),\n",
    "            ))\n",
    "            gender_fig.text(x=x_pos, y=y_pos, text=value(word))\n",
    "    gender_fig.line(\n",
    "        x=[i * pca_vector[0] for i in range(-200, 200)],\n",
    "        y=[i * pca_vector[1] for i in range(-200, 200)],\n",
    "        line_color='#C40000',\n",
    "    )\n",
    "                \n",
    "    show(gridplot([[embedding_fig, pca_fig, gender_fig]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "current word embedding debiasing techniques only look at one dimensional biases\n",
    "    eg. gender\n",
    "even then, the dimensions are not clea\n",
    "    FIXME need evidence\n",
    "interested in more complicated dimensions\n",
    "    sexuality, nationality, religion\n",
    "methods are lacking\n",
    "    majority based on rejecting dimensions\n",
    "        problematic, since it reduces \n",
    "        FIXME need evidence\n",
    "    indirect biases remain (FIXME citation needed)\n",
    "instead, alternate method based on corpus manipulation\n",
    "    randomly swap biased words, then add words back in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in some data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = Path('corpora/wikipedia-1')\n",
    "# load in the relevant data\n",
    "gender_pairs_file = Path('data/gender-pairs/definitional')\n",
    "gender_pairs = read_word_groups(gender_pairs_file)\n",
    "gendered_words = read_word_list(Path('data/gendered-words/gender_specific_seed'))\n",
    "equalize_pairs = read_word_groups(Path('data/gender-pairs/equalize'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_section('The Bolukbasi Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at gender in the un-debiased baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = create_fasttext_model(\n",
    "    corpus_path,\n",
    "    out_path=Path('models/paper-baseline.w2v')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their 2017 paper, Bolukbasi et al. uses the following words to define the gender subspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gender subspace, they first make all the word vectors relative to the midpoint of each pair of words. The first principal component of those vectors is the gender subspace. The diagram below shows a simplified example, defining a 1D gender subspace in a 2D embedding, with the first principal component shown in red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_diagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the gender pairs are not exactly aligned, the more gender pairs that are used, the more principal components there would be. Based on the definitional gender pairs used by Bolukbasi et al, PCA results in the following amount of variation expliained by each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gender_variance():\n",
    "\n",
    "    from linalg import recenter, normalize\n",
    "    import numpy as np\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    matrix = []\n",
    "    for male_word, female_word in [['man', 'woman'], ['boy', 'girl'], ['he', 'she']]:\n",
    "        if male_word not in baseline_model or female_word not in baseline_model:\n",
    "            continue\n",
    "        matrix.extend(recenter(\n",
    "            np.array([baseline_model[male_word], baseline_model[female_word]])\n",
    "        ))\n",
    "    matrix = np.array(matrix)\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(matrix)\n",
    "    components = normalize(pca.components_)\n",
    "\n",
    "    total_variance = sum(pca.explained_variance_)\n",
    "    return pca.explained_variance_ / total_variance\n",
    "\n",
    "for i, variance in enumerate(gender_variance(), start=1):\n",
    "    print(f'Component {i}: {variance:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_section('Gender is not one-dimensional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_section('Rejection degrades performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_section('Approach is valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to show that this swapping approach works. Unfortunately, the previous evaluation approach cannot be used to evaluate a swapped model, so we need a new analogical evaluation. The expected results look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "METRIC          BASELINE      SWAPPED       BOLUKBASI\n",
    "projection\n",
    "    adjectives  0.0136640928  0.0311164421  0.0000898000\n",
    "    occupation  0.0096600337  0.0103131604  0.0000000066\n",
    "analogy\n",
    "    adjectives  0.1079770610  0.0031673744  0.0000470000\n",
    "    occupation  0.0759830767  0.0007209567  0.0000000016\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this small experiment, we will use a small Wikipedia corpus, and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_approach():\n",
    "    # settings\n",
    "    corpus_path = Path('corpora/wikipedia-1')\n",
    "    # load in the relevant data\n",
    "    gender_pairs = read_gender_pairs(Path('data/gender-pairs/definitional'))\n",
    "    gender_words = read_word_list(Path('data/gendered-words/gender_specific_seed'))\n",
    "    equalize_pairs = read_gender_pairs(Path('data/gender-pairs/equalize'))\n",
    "    # create the models\n",
    "    baseline_model = load_word2vec_embedding(\n",
    "        corpus_path,\n",
    "        outpath=Path('models/paper-validation-baseline.w2v')\n",
    "    )\n",
    "    bolukbasi_model = debias_bolukbasi_original(\n",
    "        baseline_model,\n",
    "        gender_pairs,\n",
    "        gendered_words,\n",
    "        equalize_pairs,\n",
    "        outpath=Path('models/paper-validation-bolukbasi.w2v'),\n",
    "    )\n",
    "    swapped_model = load_word2vec_embedding(\n",
    "        create_randomized_swapped_corpus(\n",
    "            corpus_path,\n",
    "            gender_pairs,\n",
    "            outpath=Path('corpora/wikipedia-1-paper-swapped'),\n",
    "        ),\n",
    "        outpath=Path('models/paper-validation-swapped.w2v')\n",
    "    )\n",
    "\n",
    "# validate_approach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
