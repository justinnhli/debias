{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing Word Embeddings: An Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain, islice\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from experiments import WordEmbedding\n",
    "from experiments import read_word_list, read_gender_pairs\n",
    "from experiments import recenter, normalize, project, reject\n",
    "from experiments import define_pca_gender_direction\n",
    "from experiments import load_fasttext_embedding, load_word2vec_embedding\n",
    "from experiments import debias_bolukbasi_original\n",
    "from experiments import create_randomized_swapped_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the corpus and data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = Path('corpora/wikipedia-1')\n",
    "\n",
    "gender_pairs_file = Path('data/gender-pairs/definitional')\n",
    "gender_pairs = read_gender_pairs(gender_pairs_file)\n",
    "gendered_words = read_word_list(Path('data/gendered-words/gender_specific_seed'))\n",
    "equalize_pairs = read_gender_pairs(Path('data/gender-pairs/equalize'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the different embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = load_word2vec_embedding(\n",
    "    corpus_path,\n",
    "    out_path=Path('models/paper-validation-baseline.w2v')\n",
    ")\n",
    "bolukbasi_model = debias_bolukbasi_original(\n",
    "    baseline_model,\n",
    "    gender_pairs,\n",
    "    gendered_words,\n",
    "    equalize_pairs,\n",
    "    out_path=Path('models/paper-validation-bolukbasi.w2v'),\n",
    ")\n",
    "swapped_corpus = create_randomized_swapped_corpus(\n",
    "    corpus_path,\n",
    "    [*gender_pairs, *equalize_pairs],\n",
    ")\n",
    "swapped_model = load_fasttext_embedding(\n",
    "    swapped_corpus,\n",
    "    method='cbow',\n",
    "    out_path=Path('models/paper-validation-swapped.w2v'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the different word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = read_word_list(Path('data/swap-groups/races'))\n",
    "nationalities = read_word_list(Path('data/swap-groups/nationalities'))\n",
    "occupations = read_word_list(Path('data/biased-words/occupations'))\n",
    "adjectives = read_word_list(Path('data/biased-words/adjectives'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_sum(seq):\n",
    "    \"\"\"Calculate the cumulative sum of a sequence of numbers.\n",
    "    \n",
    "    Parameters:\n",
    "        seq (Sequence[float]): The sequence of numbers.\n",
    "        \n",
    "    Yields:\n",
    "        float: The cumulative sum.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for x in seq:\n",
    "        total += x\n",
    "        yield total\n",
    "\n",
    "def find_elbows(seq):\n",
    "    \"\"\"Find the \"elbows\" for PCA/clustering.\n",
    "    \n",
    "    Parameters:\n",
    "        seq (Sequence[float]): The sequence of variance explained.\n",
    "        \n",
    "    Returns:\n",
    "        List[Tuple[float, int]]: List of (score, index) tuples, in decreasing order.\n",
    "    \"\"\"\n",
    "    cum_sum = list(cumulative_sum(seq))\n",
    "    scores = []\n",
    "    for i, (a, b, c) in enumerate(zip(cum_sum[:-2], cum_sum[1:-1], cum_sum[2:])):\n",
    "        proportion = (b - a) / (c - a)\n",
    "        absolute = b - (a + (c - a) / 2)\n",
    "        scores.append((proportion, i))\n",
    "    return sorted(scores, reverse=True)\n",
    "\n",
    "def measure_embedding_similarity(embeddings, num_words=100):\n",
    "    \"\"\"Measure the distance between word embeddings.\n",
    "\n",
    "    Parameters:\n",
    "        embeddings (List[WordEmbedding]): The embeddings to compare.\n",
    "        num_words (int): The number of words to measure distance on, creating\n",
    "            num_words**2 pairs. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: A symmetric matrix of similarities.\n",
    "    \"\"\"\n",
    "    vocabulary = None\n",
    "    num_embeddings = len(embeddings)\n",
    "    word_distances = [{} for _ in range(num_embeddings)]\n",
    "    for embedding_id, embedding in enumerate(embeddings):\n",
    "        if vocabulary is None:\n",
    "            rng = Random(8675309)\n",
    "            vocabulary = rng.sample(list(embedding.words), num_words)\n",
    "        for i, word1 in enumerate(vocabulary[:-1]):\n",
    "            for word2 in vocabulary[i+1:]:\n",
    "                word_distances[embedding_id][(word1, word2)] = embedding.distance(word1, word2)\n",
    "    distances = []\n",
    "    for embedding1_id, embedding2_id in zip(range(num_embeddings - 1), range(1, num_embeddings)):\n",
    "        pass\n",
    "        '''FIXME\n",
    "        what are some methods for comparing embeddings?\n",
    "            count the overlap in the top-ten most-similar words (higher is better)\n",
    "                https://towardsdatascience.com/comparing-word-embeddings-c2efd2455fe3\n",
    "            measure average distance between word pairs (lower is better)\n",
    "            https://www.sciencedirect.com/science/article/pii/S1045926X18301241\n",
    "            https://www.aclweb.org/anthology/D15-1036\n",
    "        '''\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are near the \"main\" races?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in sorted(races):\n",
    "    print(race)\n",
    "    for nearby, distance in baseline_model.words_near_word(race):\n",
    "        print(f'    {nearby} ({distance:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the dimension of the race subspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [list(baseline_model[race]) for race in races]\n",
    "centered = recenter(np.array(matrix))\n",
    "pca = PCA(n_components=len(races))\n",
    "pca.fit(centered)\n",
    "for component, variance_percent in zip(pca.components_, pca.explained_variance_ratio_):\n",
    "    print(f'{variance_percent:.3%}')\n",
    "race_subspace = normalize(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are fewer dimensions here than the number of \"races\", which is to be expected. I'm surprised the subspace is this large though - I would have thought it would just be 2-3 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the dimension of the nationalities subspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(nationalities)} nationalities: {\", \".join(sorted(nationalities))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    list(baseline_model[nationality.lower()])\n",
    "    for nationality in nationalities\n",
    "    if nationality.lower() in baseline_model\n",
    "]\n",
    "centered = recenter(np.array(matrix))\n",
    "pca = PCA(n_components=min(len(matrix), len(matrix[0])))\n",
    "pca.fit(centered)\n",
    "for component, variance_percent in islice(zip(pca.components_, pca.explained_variance_ratio_), 20):\n",
    "    print(f'{variance_percent:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using nationalities showcases the problems: there are more nationalities than there are dimensions, and although the variance explains drops off, there is no clear cutoff point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    list(baseline_model[nationality.lower()])\n",
    "    for nationality in nationalities\n",
    "    if nationality.lower() in baseline_model\n",
    "]\n",
    "centered = recenter(np.array(matrix))\n",
    "pca = PCA(n_components=min(len(matrix), len(matrix[0])))\n",
    "pca.fit(centered)\n",
    "cum_var = list(cumulative_sum(pca.explained_variance_ratio_))\n",
    "print(cum_var)\n",
    "\n",
    "\n",
    "\n",
    "def find_thresholds(thresholds, sequence):\n",
    "    threshold_index = 0\n",
    "    var_index = 0\n",
    "    while threshold_index < len(thresholds) and var_index < len(cum_var):\n",
    "        variance = sequence[var_index]\n",
    "        if variance > thresholds[threshold_index]:\n",
    "            yield var_index\n",
    "            threshold_index += 1\n",
    "        var_index += 1\n",
    "            \n",
    "\n",
    "thresholds = [n / 10 for n in range(2, 10, 2)]\n",
    "print(list(find_thresholds(thresholds, cum_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the dimension of the gender subspace?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seemingly obvious question is about whether you can just through pairs of gendered words into PCA and recover the single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_words = read_word_list(Path('data/gender-pairs/definitional'))\n",
    "matrix = [list(baseline_model[word]) for word in gender_words if word in baseline_model]\n",
    "centered = recenter(np.array(matrix))\n",
    "pca = PCA(n_components=len(matrix))\n",
    "pca.fit(centered)\n",
    "for component, variance_percent in zip(pca.components_, pca.explained_variance_ratio_):\n",
    "    print(f'{variance_percent:.3%}')\n",
    "gender_subspace = normalize(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to suggest that you *can't* just throw gender into PCA in this way, which I think means this \"gender pair\" method is somewhat fragile. How will you know if you can throw other linear subspaces (eg. age) into PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow-up question: since we do have a \"ground truth\" using the per-pair PCA method, how do these components compare to that vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gender_pairs = read_gender_pairs(Path('data/gender-pairs/definitional')) \n",
    "bolukbasi_gender_direction = define_pca_gender_direction(baseline_model, gender_pairs)\n",
    "\n",
    "\n",
    "gender_words = read_word_list(Path('data/gender-pairs/definitional'))\n",
    "matrix = [list(baseline_model[word]) for word in gender_words if word in baseline_model]\n",
    "centered = recenter(np.array(matrix))\n",
    "pca = PCA(n_components=len(matrix))\n",
    "pca.fit(centered)\n",
    "gender_subspace = normalize(pca.components_)\n",
    "for i, (component, variance_percent) in enumerate(zip(gender_subspace, pca.explained_variance_ratio_), start=1):\n",
    "    print(' '.join([\n",
    "        f'Component {i}:',\n",
    "        f'{variance_percent:.3%} variance explained,',\n",
    "        f'groundtruth projection {np.linalg.norm(project(bolukbasi_gender_direction, component)):.3f}',\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would not have expected this result - since all vectors are normalized, a projection of ~0.5 would mean that the angle is ~acos(0.5/1) = ~60 degrees. The interesting thing is that the this doesn't correlate with the amount of variance explained: components 1, 2, 5, 6 have around 60 degree angle, while components 3, 4 are practically orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do think this is a meaningful result for debiasing in general - that figuring out the subspace is complicated in the first place. Even with just binary gender there are multiple methods (centroid of pairs, PCA of pairs, PCA of words), and it becomes more complicated with non-linear subspaces. This bolsters the argument for a non-subspace-based debiasing method - assuming we can find differences in results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are there words that lose meaning if we remove their racial components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We answer this by looking for words whose component in the racial subspace is larger than the other component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_component = project(baseline_model.vectors, race_subspace)\n",
    "print(projected_component.shape)\n",
    "projected_norms = np.linalg.norm(projected_component, axis=1)\n",
    "print(projected_norms.shape)\n",
    "rejected_component = baseline_model.vectors - projected_component\n",
    "print(rejected_component.shape)\n",
    "rejected_norms = np.linalg.norm(rejected_component, axis=1)\n",
    "print(rejected_norms.shape)\n",
    "indicator = (projected_norms > rejected_norms)\n",
    "print(indicator.shape)\n",
    "for word, in_subspace in zip(baseline_model.words, indicator):\n",
    "    if in_subspace:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is no. I suspect the curse of dimensionality is in play here: with 100 total dimensions and only 2-3 racial dimensions, it will never be the majority component except for the words we are doing the PCA on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the words near adjectives and occupations different between the different embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "limit = 10\n",
    "rows = []\n",
    "for index, word in enumerate(chain(adjectives, occupations)):\n",
    "    for model_name, model in [('bolukbasi', bolukbasi_model), ('swapped', swapped_model)]:\n",
    "        for nearby, distance in model.words_near_word(word):\n",
    "            rows.append([word, model_name, nearby, distance])\n",
    "    if index > limit:\n",
    "        break\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
